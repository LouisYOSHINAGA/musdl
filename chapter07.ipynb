{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycYtCHu8BkdY"
      },
      "outputs": [],
      "source": [
        "!pip install pretty_midi\n",
        "!pip install midi2audio\n",
        "!apt install fluidsynth\n",
        "!pip install tensorflow==2.15\n",
        "!pip install tensorflow-probability==0.23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0nRolvU3bE6"
      },
      "outputs": [],
      "source": [
        "import glob, random\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import matplotlib.pyplot as plt\n",
        "from midi2audio import FluidSynth\n",
        "import IPython.display as ipd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGnOOK1P3Tw1"
      },
      "outputs": [],
      "source": [
        "class UnsupportedMidiFileException(Exception):\n",
        "    \"Unsupported MIDI File\"\n",
        "\n",
        "def transpose_to_c(midi: pretty_midi.PrettyMIDI, key_number: int) -> None:\n",
        "    for inst in midi.instruments:\n",
        "        if not inst.is_drum:\n",
        "            for note in inst.notes:\n",
        "                note.pitch -= key_number % 12\n",
        "\n",
        "def get_pianoroll(midi: pretty_midi.PrettyMIDI, note_low: int, note_high: int, seqlen: int, tempo: float) -> np.ndarray:\n",
        "    pianoroll: np.ndarray = midi.get_piano_roll(fs=2*tempo/60)\n",
        "    if pianoroll.shape[1] < seqlen:\n",
        "        raise UnsupportedMidiFileException\n",
        "    pianoroll = pianoroll[note_low:note_high, 0:seqlen]\n",
        "    pianoroll = np.heaviside(pianoroll, 0)\n",
        "    return np.transpose(pianoroll)\n",
        "\n",
        "def read_midi(filename: str, is_sep_sop_alt: bool, seqlen: int) -> tuple[np.ndarray, np.ndarray, np.ndarray] \\\n",
        "                                                                 | tuple[np.ndarray, np.ndarray]:\n",
        "    midi = pretty_midi.PrettyMIDI(filename)\n",
        "    if len(midi.key_signature_changes) != 1:\n",
        "        raise UnsupportedMidiFileException\n",
        "\n",
        "    key_number: int = midi.key_signature_changes[0].key_number\n",
        "    transpose_to_c(midi, key_number)\n",
        "    key_mode: np.ndarray = np.array([int(key_number/12)])\n",
        "    tempo_time, tempo = midi.get_tempo_changes()\n",
        "    if len(tempo) != 1:\n",
        "        raise UnsupportedMidiFileException\n",
        "\n",
        "    if is_sep_sop_alt:\n",
        "        if len(midi.instruments) < 2:\n",
        "            raise UnsupportedMidiFileException\n",
        "        pianoroll_sop: np.ndarray = get_pianoroll(midi.instruments[0], 36, 84, seqlen, tempo[0])\n",
        "        pianoroll_alt: np.ndarray = get_pianoroll(midi.instruments[1], 36, 84, seqlen, tempo[0])\n",
        "        return pianoroll_sop, pianoroll_alt, key_mode\n",
        "    else:\n",
        "        pianoroll: np.ndarray = get_pianoroll(midi, 36, 84, seqlen, tempo[0])\n",
        "        return pianoroll, key_mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVs7bfBhv555"
      },
      "outputs": [],
      "source": [
        "def make_midi(pianorolls: list[np.ndarray], filename: str) -> None:\n",
        "    midi: pretty_midi.PrettyMIDI = pretty_midi.PrettyMIDI(resolution=480)\n",
        "    for pianoroll in pianorolls:\n",
        "        inst: pretty_midi.Instrument = pretty_midi.Instrument(program=1)\n",
        "        for i in range(pianoroll.shape[0]):\n",
        "            for j in range(pianoroll.shape[1]):\n",
        "                if pianoroll[i,j] > 0.5:\n",
        "                    inst.notes.append(\n",
        "                        pretty_midi.Note(start=i/2, end=(i+1)/2, pitch=j+36, velocity=100)\n",
        "                    )\n",
        "        midi.instruments.append(inst)\n",
        "    midi.write(filename)\n",
        "\n",
        "def show_and_play_midi(pianorolls: list[np.ndarray], filename: str) -> None:\n",
        "    for pianoroll in pianorolls:\n",
        "        plt.matshow(np.transpose(pianoroll))\n",
        "        plt.show()\n",
        "    make_midi(pianorolls, filename)\n",
        "\n",
        "    fs: FluidSynth = FluidSynth(sound_font=\"/usr/share/sounds/sf2/FluidR3_GM.sf2\")\n",
        "    fs.midi_to_audio(filename, \"output.wav\")\n",
        "    ipd.display(ipd.Audio(\"output.wav\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1bni0X75eXG"
      },
      "outputs": [],
      "source": [
        "dir: str = \"/content/drive/MyDrive/impl/musdl/chorales/midi/\"\n",
        "filenames: list[str] = []\n",
        "xs: list[np.ndarray] = []\n",
        "\n",
        "for f in glob.glob(f\"{dir}*.mid\"):\n",
        "    print(f)\n",
        "    try:\n",
        "        x, _ = read_midi(f, is_sep_sop_alt=False, seqlen=32)\n",
        "        filenames.append(f)\n",
        "        xs.append(x)\n",
        "    except UnsupportedMidiFileException:\n",
        "        print(\"skip\")\n",
        "\n",
        "x_all: np.ndarray = np.array(xs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wazdk5h_72ub"
      },
      "outputs": [],
      "source": [
        "print(x_all.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-lfGhxH3PeM"
      },
      "outputs": [],
      "source": [
        "seq_length: int = x_all.shape[1]\n",
        "input_dim: int = x_all.shape[2]\n",
        "encoded_dim: int = 16\n",
        "hidden_dim: int = 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mq_B_e8KQljK"
      },
      "outputs": [],
      "source": [
        "prior: tfp.distributions.Independent = tfp.distributions.Independent(\n",
        "    tfp.distributions.Normal(loc=tf.zeros(encoded_dim), scale=1),\n",
        "    reinterpreted_batch_ndims=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWebC_TU3R0M"
      },
      "outputs": [],
      "source": [
        "encoder: tf.keras.Sequential = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(\n",
        "        shape=(seq_length, input_dim, 1)\n",
        "    ),\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=hidden_dim, kernel_size=(1, input_dim), strides=1, padding=\"valid\", activation=\"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=hidden_dim, kernel_size=(4, 1), strides=(4, 1), padding=\"valid\", activation=\"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=hidden_dim, kernel_size=(4, 1), strides=(4, 1), padding=\"valid\", activation=\"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(\n",
        "        tfp.layers.MultivariateNormalTriL.params_size(encoded_dim), activation=None\n",
        "    ),\n",
        "    tfp.layers.MultivariateNormalTriL(\n",
        "        encoded_dim,\n",
        "        activity_regularizer=tfp.layers.KLDivergenceRegularizer(prior, weight=0.001)\n",
        "    )\n",
        "])\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXSK51w1-D-h"
      },
      "outputs": [],
      "source": [
        "decoder: tf.keras.Sequential = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(\n",
        "        hidden_dim, input_dim=encoded_dim, activation=\"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.Reshape(\n",
        "        target_shape=(1, 1, hidden_dim)\n",
        "    ),\n",
        "\n",
        "    tf.keras.layers.Conv2DTranspose(\n",
        "        filters=hidden_dim, kernel_size=(4, 1), strides=(4, 1), padding=\"valid\", activation=\"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "    tf.keras.layers.Conv2DTranspose(\n",
        "        filters=hidden_dim, kernel_size=(4, 1), strides=(4, 1), padding=\"valid\", activation=\"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "    tf.keras.layers.Conv2DTranspose(\n",
        "        filters=hidden_dim, kernel_size=(2, 1), strides=(2, 1), padding=\"valid\", activation=\"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(0.3),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.Conv2DTranspose(\n",
        "        filters=1, kernel_size=(1, input_dim), strides=1, padding=\"valid\", activation=\"sigmoid\"\n",
        "    )\n",
        "])\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx51rLUM-CgS"
      },
      "outputs": [],
      "source": [
        "vae: tf.keras.Model = tf.keras.Model(encoder.inputs, decoder(encoder.outputs))\n",
        "vae.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=\"binary_accuracy\"\n",
        ")\n",
        "vae.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWf5C1j8-JqZ"
      },
      "outputs": [],
      "source": [
        "vae.fit(x_all, x_all, batch_size=32, epochs=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fp2Tft_ea9-X"
      },
      "outputs": [],
      "source": [
        "rng: np.random.Generator = np.random.default_rng()\n",
        "z: np.ndarray = rng.multivariate_normal(np.zeros(encoded_dim), np.identity(encoded_dim))\n",
        "x: np.ndarray = decoder.predict(np.array([z]))\n",
        "show_and_play_midi([np.squeeze(x)], \"output.mid\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "10QX6E1wzligKt-FNEVduXoB7ndpzQsNX",
      "authorship_tag": "ABX9TyOGRkaa9XlECjTBhgJ4PLxL"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}