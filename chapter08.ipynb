{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycYtCHu8BkdY"
      },
      "outputs": [],
      "source": [
        "!pip install pretty_midi\n",
        "!pip install midi2audio\n",
        "!apt install fluidsynth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0nRolvU3bE6"
      },
      "outputs": [],
      "source": [
        "import glob, random\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from midi2audio import FluidSynth\n",
        "import IPython.display as ipd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices(\"GPU\")"
      ],
      "metadata": {
        "id": "dzQNna1zMa6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGnOOK1P3Tw1"
      },
      "outputs": [],
      "source": [
        "class UnsupportedMidiFileException(Exception):\n",
        "    \"Unsupported MIDI File\"\n",
        "\n",
        "def transpose_to_c(midi: pretty_midi.PrettyMIDI, key_number: int) -> None:\n",
        "    for inst in midi.instruments:\n",
        "        if not inst.is_drum:\n",
        "            for note in inst.notes:\n",
        "                note.pitch -= key_number % 12\n",
        "\n",
        "def get_pianoroll(midi: pretty_midi.PrettyMIDI, note_low: int, note_high: int, seqlen: int, tempo: float) -> np.ndarray:\n",
        "    pianoroll: np.ndarray = midi.get_piano_roll(fs=2*tempo/60)\n",
        "    if pianoroll.shape[1] < seqlen:\n",
        "        raise UnsupportedMidiFileException\n",
        "    pianoroll = pianoroll[note_low:note_high, 0:seqlen]\n",
        "    pianoroll = np.heaviside(pianoroll, 0)\n",
        "    return np.transpose(pianoroll)\n",
        "\n",
        "def read_midi(filename: str, is_sep_sop_alt: bool, seqlen: int) -> tuple[np.ndarray, np.ndarray, np.ndarray] \\\n",
        "                                                                 | tuple[np.ndarray, np.ndarray]:\n",
        "    midi = pretty_midi.PrettyMIDI(filename)\n",
        "    if len(midi.key_signature_changes) != 1:\n",
        "        raise UnsupportedMidiFileException\n",
        "\n",
        "    key_number: int = midi.key_signature_changes[0].key_number\n",
        "    transpose_to_c(midi, key_number)\n",
        "    key_mode: np.ndarray = np.array([int(key_number/12)])\n",
        "    tempo_time, tempo = midi.get_tempo_changes()\n",
        "    if len(tempo) != 1:\n",
        "        raise UnsupportedMidiFileException\n",
        "\n",
        "    if is_sep_sop_alt:\n",
        "        if len(midi.instruments) < 2:\n",
        "            raise UnsupportedMidiFileException\n",
        "        pianoroll_sop: np.ndarray = get_pianoroll(midi.instruments[0], 36, 84, seqlen, tempo[0])\n",
        "        pianoroll_alt: np.ndarray = get_pianoroll(midi.instruments[1], 36, 84, seqlen, tempo[0])\n",
        "        return pianoroll_sop, pianoroll_alt, key_mode\n",
        "    else:\n",
        "        pianoroll: np.ndarray = get_pianoroll(midi, 36, 84, seqlen, tempo[0])\n",
        "        return pianoroll, key_mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVs7bfBhv555"
      },
      "outputs": [],
      "source": [
        "def make_midi(pianorolls: list[np.ndarray], filename: str) -> None:\n",
        "    midi: pretty_midi.PrettyMIDI = pretty_midi.PrettyMIDI(resolution=480)\n",
        "    for pianoroll in pianorolls:\n",
        "        inst: pretty_midi.Instrument = pretty_midi.Instrument(program=1)\n",
        "        for i in range(pianoroll.shape[0]):\n",
        "            for j in range(pianoroll.shape[1]):\n",
        "                if pianoroll[i,j] > 0.5:\n",
        "                    inst.notes.append(\n",
        "                        pretty_midi.Note(start=i/2, end=(i+1)/2, pitch=j+36, velocity=100)\n",
        "                    )\n",
        "        midi.instruments.append(inst)\n",
        "    midi.write(filename)\n",
        "\n",
        "def show_and_play_midi(pianorolls: list[np.ndarray], filename: str) -> None:\n",
        "    for pianoroll in pianorolls:\n",
        "        plt.matshow(np.transpose(pianoroll))\n",
        "        plt.show()\n",
        "    make_midi(pianorolls, filename)\n",
        "\n",
        "    fs: FluidSynth = FluidSynth(sound_font=\"/usr/share/sounds/sf2/FluidR3_GM.sf2\")\n",
        "    fs.midi_to_audio(filename, \"output.wav\")\n",
        "    ipd.display(ipd.Audio(\"output.wav\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1bni0X75eXG"
      },
      "outputs": [],
      "source": [
        "dir: str = \"/content/drive/MyDrive/impl/musdl/chorales/midi/\"\n",
        "filenames: list[str] = []\n",
        "xs: list[np.ndarray] = []\n",
        "\n",
        "for f in glob.glob(f\"{dir}*.mid\"):\n",
        "    print(f)\n",
        "    try:\n",
        "        x, _ = read_midi(f, is_sep_sop_alt=False, seqlen=16)\n",
        "        filenames.append(f)\n",
        "        xs.append(x)\n",
        "    except UnsupportedMidiFileException:\n",
        "        print(\"skip\")\n",
        "\n",
        "x_all: np.ndarray = np.expand_dims(np.array(xs), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wazdk5h_72ub"
      },
      "outputs": [],
      "source": [
        "print(x_all.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-lfGhxH3PeM"
      },
      "outputs": [],
      "source": [
        "seq_length: int = x_all.shape[1]\n",
        "dim: int = x_all.shape[2]\n",
        "encoded_dim: int = 32\n",
        "hidden_dim: int = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWebC_TU3R0M"
      },
      "outputs": [],
      "source": [
        "generator: tf.keras.Sequential = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(encoded_dim, )),\n",
        "    tf.keras.layers.Dense(hidden_dim),\n",
        "    tf.keras.layers.LeakyReLU(0.3),\n",
        "    tf.keras.layers.Reshape(\n",
        "        target_shape=(1, 1, hidden_dim)\n",
        "    ),\n",
        "    tf.keras.layers.Conv2DTranspose(\n",
        "        hidden_dim, (4, 1), strides=(4, 1), padding=\"valid\"\n",
        "    ),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "    tf.keras.layers.Conv2DTranspose(\n",
        "        hidden_dim, (4, 1), strides=(4, 1), padding=\"valid\"\n",
        "    ),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "    tf.keras.layers.Conv2DTranspose(\n",
        "        1, (1, dim), strides=1, padding=\"valid\", activation=\"sigmoid\"\n",
        "    ),\n",
        "])\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXSK51w1-D-h",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "discriminator: tf.keras.Sequential = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(seq_length, dim, 1)),\n",
        "    tf.keras.layers.Conv2D(\n",
        "        hidden_dim, (1, dim), strides=1, padding=\"valid\"\n",
        "    ),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "    tf.keras.layers.Conv2D(\n",
        "        hidden_dim, (4, 1), strides=(4, 1), padding=\"valid\"\n",
        "    ),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "    tf.keras.layers.Conv2D(\n",
        "        hidden_dim, (4, 1), strides=(4, 1), padding=\"valid\"\n",
        "    ),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(0.3),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(1, use_bias=True, activation=\"sigmoid\")\n",
        "])\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n",
        "discriminator.trainable = False\n",
        "\n",
        "gan = tf.keras.Model(generator.inputs, discriminator(generator.outputs))\n",
        "gan.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])"
      ],
      "metadata": {
        "id": "euc1iOuWv0FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_noisy: bool = True\n",
        "iterations: int = 10000\n",
        "batch_size: int = 64\n",
        "\n",
        "idx_from: int = 0\n",
        "for step in range(1, iterations+1):\n",
        "    # train discriminator\n",
        "    rvs: np.ndarray = np.random.normal(size=(batch_size, encoded_dim))  # seed for generation\n",
        "    print(rvs.shape)\n",
        "    x_gen: np.ndarray = generator.predict(rvs, verbose=0)  # generated pianoroll\n",
        "    x_real: np.ndarray = x_all[idx_from:idx_from+batch_size]  # real pianoroll\n",
        "    x: np.ndarray = np.concatenate([x_real, x_gen])\n",
        "    print(x.shape)\n",
        "\n",
        "    # make label: fake=1, real=0\n",
        "    if label_noisy:\n",
        "        labels: np.ndarray = np.concatenate([\n",
        "            np.zeros((batch_size, 1)) + 0.2 * np.abs(np.random.random((batch_size, 1))),\n",
        "            np.ones((batch_size, 1)) - 0.2 * np.abs(np.random.random((batch_size, 1)))\n",
        "        ])\n",
        "    else:\n",
        "        labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
        "\n",
        "    loss = discriminator.train_on_batch(x, labels)\n",
        "    if step % 50 == 0:\n",
        "        print(f\"{step}: D loss = {loss}\")\n",
        "\n",
        "    # train generator\n",
        "    rvs = np.random.normal(size=(batch_size, encoded_dim))  # seed for generation\n",
        "    mislead_labels: np.ndarray = np.ones((batch_size, 1))  # label for discriminator\n",
        "    for i in range(5):\n",
        "        loss = gan.train_on_batch(rvs, mislead_labels)\n",
        "    if step % 50 == 0:\n",
        "        print(f\"{step}: G loss = {loss}\")\n",
        "\n",
        "    idx_from += batch_size\n",
        "    if idx_from + batch_size > len(x_all):\n",
        "        idx_from = 0"
      ],
      "metadata": {
        "id": "_ydzJKzUxvUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_z: np.ndarray = np.random.multivariate_normal(\n",
        "    np.zeros(encoded_dim), np.identity(encoded_dim)\n",
        ")\n",
        "print(my_z)\n",
        "\n",
        "my_x = generator.predict(np.array([my_z]))\n",
        "show_and_play_midi([np.squeeze(my_x)], \"output.mid\")"
      ],
      "metadata": {
        "id": "wV2Atw9J4QpY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1IKJveMl3DqgWDFvGqq4RcnhJUyC1ElhH",
      "authorship_tag": "ABX9TyODeilJ/l2qQkvGmR27AzgV"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}